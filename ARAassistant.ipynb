{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F6joXOWBBdj5"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai python-dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epoJToQPDE1Z"
      },
      "source": [
        "Key integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO2l08r_EImO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slV_rUK-DCV-"
      },
      "source": [
        "LLM Wrapper Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fY_0o9I3DEEg"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import time\n",
        "from typing import Optional, Dict\n",
        "\n",
        "class OpenAILLM:\n",
        "    \"\"\"\n",
        "    Minimal OpenAI LLM wrapper for agentic systems (Colab-friendly)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: str = \"gpt-4o-mini\",\n",
        "        temperature: float = 0.2,\n",
        "        max_tokens: int = 1024,\n",
        "    ):\n",
        "        self.client = OpenAI()\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        system_prompt: Optional[str] = None,\n",
        "    ) -> Dict:\n",
        "        messages = []\n",
        "\n",
        "        if system_prompt:\n",
        "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            temperature=self.temperature,\n",
        "            max_tokens=self.max_tokens,\n",
        "        )\n",
        "\n",
        "        latency = round(time.time() - start_time, 3)\n",
        "\n",
        "        return {\n",
        "            \"text\": response.choices[0].message.content,\n",
        "            \"latency\": latency,\n",
        "            \"tokens\": response.usage.total_tokens,\n",
        "        }\n",
        "\n",
        "    def stream(self, prompt: str):\n",
        "        stream = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            stream=True,\n",
        "        )\n",
        "\n",
        "        for chunk in stream:\n",
        "            if chunk.choices[0].delta.get(\"content\"):\n",
        "                yield chunk.choices[0].delta[\"content\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGEVnt8EQgF"
      },
      "source": [
        "Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNwx3Nc_ESN-",
        "outputId": "9ba25143-b5c1-4b57-891f-952669eed1b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RESPONSE\n",
            "Agentic AI refers to artificial intelligence systems that can act independently and make decisions on their own, rather than just following pre-programmed instructions. Think of it like a smart assistant that can understand a situation, weigh options, and choose a course of action based on its understanding of the world.\n",
            "\n",
            "For example, if you have an agentic AI in a smart home, it could learn your preferences and decide to adjust the temperature or turn on the lights without you having to tell it every time. It has a level of autonomy and can adapt to new situations, making it more flexible and useful in various tasks. However, this also raises important questions about control, safety, and ethics, as these systems become more capable of making decisions that affect our lives.\n",
            "\n",
            " METADATA \n",
            "Latency: 8.792 seconds\n",
            "Tokens used: 174\n"
          ]
        }
      ],
      "source": [
        "llm = OpenAILLM(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "response = llm.generate(\n",
        "    prompt=\"Explain agentic AI in simple terms\",\n",
        "    system_prompt=\"You are an AI professor.\"\n",
        ")\n",
        "\n",
        "print(\"RESPONSE\")\n",
        "print(response[\"text\"])\n",
        "\n",
        "print(\"\\n METADATA \")\n",
        "print(\"Latency:\", response[\"latency\"], \"seconds\")\n",
        "print(\"Tokens used:\", response[\"tokens\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgeismD0EWFh"
      },
      "source": [
        "Streaming test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e151rBfEYP1",
        "outputId": "77262e00-25e9-402f-982e-dbbaa39f5be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STREAMING OUTPUT\n",
            "Agentic AI refers to artificial intelligence systems that possess the capability to act autonomously and make decisions based on their programmed goals and environmental interactions."
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "print(\"STREAMING OUTPUT\")\n",
        "\n",
        "stream = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Give a one-line definition of agentic AI\"}],\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content:\n",
        "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
